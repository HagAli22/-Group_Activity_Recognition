2025-09-28 23:13:13 - root - INFO - Starting Baseline_B7_step_B Training
2025-09-28 23:13:13 - root - INFO - Training videos: 24 videos
2025-09-28 23:13:13 - root - INFO - Validation videos: 15 videos
2025-09-28 23:13:13 - root - INFO - Training video IDs: [1, 3, 6, 7, 10, 13, 15, 16, 18, 22, 23, 31, 32, 36, 38, 39, 40, 41, 42, 48, 50, 52, 53, 54]
2025-09-28 23:13:13 - root - INFO - Validation video IDs: [0, 2, 8, 12, 17, 19, 24, 26, 27, 28, 30, 33, 46, 49, 51]
2025-09-28 23:13:14 - root - INFO - Using device: cuda
2025-09-28 23:13:25 - root - INFO - Training dataset size: 2152
2025-09-28 23:13:25 - root - INFO - Validation dataset size: 1341
2025-09-28 23:19:18 - root - INFO - Checkpoint directory created: Baseline_B7/checkpoints
2025-09-28 23:19:18 - root - INFO - Starting training for 25 epochs
2025-09-28 23:19:18 - root - INFO - Starting epoch 1/25
2025-09-28 23:20:38 - root - INFO -   Batch 50/269 - Loss: 0.2101, Acc: 17.75%
2025-09-28 23:21:50 - root - INFO -   Batch 100/269 - Loss: 0.2097, Acc: 25.37%
2025-09-28 23:23:04 - root - INFO -   Batch 150/269 - Loss: 0.1607, Acc: 31.25%
2025-09-28 23:24:17 - root - INFO -   Batch 200/269 - Loss: 0.1287, Acc: 35.88%
2025-09-28 23:25:31 - root - INFO -   Batch 250/269 - Loss: 0.1364, Acc: 41.20%
2025-09-28 23:25:58 - root - INFO - Running validation...
2025-09-28 23:29:48 - root - INFO - Checkpoint saved for epoch 1 at Baseline_B7/checkpoints/checkpoint_epoch_1.pth
2025-09-28 23:29:48 - root - INFO - Epoch 1/25 Results:
2025-09-28 23:29:48 - root - INFO -   Train Loss: 0.1736, Train Acc: 43.36%
2025-09-28 23:29:48 - root - INFO -   Val Loss: 0.1304, Val Acc: 65.92%
2025-09-28 23:29:48 - root - INFO -   Learning Rate: 0.000400
2025-09-28 23:29:48 - root - INFO - ------------------------------------------------------------
2025-09-28 23:29:48 - root - INFO - New best model saved with validation loss: 0.1304
2025-09-28 23:29:48 - root - INFO - Best model saved to: Baseline_B7/checkpoints/best_best_Baseline_B7_B_model.pth
2025-09-28 23:29:48 - root - INFO - Starting epoch 2/25
2025-09-28 23:31:08 - root - INFO -   Batch 50/269 - Loss: 0.0796, Acc: 73.75%
2025-09-28 23:32:22 - root - INFO -   Batch 100/269 - Loss: 0.0646, Acc: 75.12%
2025-09-28 23:33:36 - root - INFO -   Batch 150/269 - Loss: 0.0897, Acc: 77.00%
2025-09-28 23:34:48 - root - INFO -   Batch 200/269 - Loss: 0.0682, Acc: 76.56%
2025-09-28 23:36:02 - root - INFO -   Batch 250/269 - Loss: 0.1420, Acc: 77.10%
2025-09-28 23:36:28 - root - INFO - Running validation...
2025-09-28 23:40:13 - root - INFO - Checkpoint saved for epoch 2 at Baseline_B7/checkpoints/checkpoint_epoch_2.pth
2025-09-28 23:40:13 - root - INFO - Epoch 2/25 Results:
2025-09-28 23:40:13 - root - INFO -   Train Loss: 0.1092, Train Acc: 77.79%
2025-09-28 23:40:13 - root - INFO -   Val Loss: 0.1131, Val Acc: 75.32%
2025-09-28 23:40:13 - root - INFO -   Learning Rate: 0.000400
2025-09-28 23:40:13 - root - INFO - ------------------------------------------------------------
2025-09-28 23:40:13 - root - INFO - New best model saved with validation loss: 0.1131
2025-09-28 23:40:13 - root - INFO - Best model saved to: Baseline_B7/checkpoints/best_best_Baseline_B7_B_model.pth
2025-09-28 23:40:13 - root - INFO - Starting epoch 3/25
2025-09-28 23:41:31 - root - INFO -   Batch 50/269 - Loss: 0.1279, Acc: 86.00%
2025-09-28 23:42:44 - root - INFO -   Batch 100/269 - Loss: 0.0624, Acc: 87.62%
2025-09-28 23:43:57 - root - INFO -   Batch 150/269 - Loss: 0.0741, Acc: 86.00%
2025-09-28 23:45:11 - root - INFO -   Batch 200/269 - Loss: 0.0788, Acc: 85.75%
2025-09-28 23:46:26 - root - INFO -   Batch 250/269 - Loss: 0.0595, Acc: 85.80%
2025-09-28 23:46:52 - root - INFO - Running validation...
2025-09-28 23:50:31 - root - INFO - Checkpoint saved for epoch 3 at Baseline_B7/checkpoints/checkpoint_epoch_3.pth
2025-09-28 23:50:31 - root - INFO - Epoch 3/25 Results:
2025-09-28 23:50:31 - root - INFO -   Train Loss: 0.0920, Train Acc: 85.78%
2025-09-28 23:50:31 - root - INFO -   Val Loss: 0.1158, Val Acc: 75.84%
2025-09-28 23:50:31 - root - INFO -   Learning Rate: 0.000400
2025-09-28 23:50:31 - root - INFO - ------------------------------------------------------------
2025-09-28 23:50:31 - root - INFO - Starting epoch 4/25
2025-09-28 23:51:49 - root - INFO -   Batch 50/269 - Loss: 0.0707, Acc: 87.25%
2025-09-28 23:53:00 - root - INFO -   Batch 100/269 - Loss: 0.0590, Acc: 88.75%
2025-09-28 23:54:13 - root - INFO -   Batch 150/269 - Loss: 0.0725, Acc: 88.25%
2025-09-28 23:55:27 - root - INFO -   Batch 200/269 - Loss: 0.0838, Acc: 87.94%
2025-09-28 23:56:39 - root - INFO -   Batch 250/269 - Loss: 0.0880, Acc: 88.00%
2025-09-28 23:57:06 - root - INFO - Running validation...
2025-09-29 00:00:48 - root - INFO - Checkpoint saved for epoch 4 at Baseline_B7/checkpoints/checkpoint_epoch_4.pth
2025-09-29 00:00:48 - root - INFO - Epoch 4/25 Results:
2025-09-29 00:00:48 - root - INFO -   Train Loss: 0.0868, Train Acc: 88.15%
2025-09-29 00:00:48 - root - INFO -   Val Loss: 0.1071, Val Acc: 80.09%
2025-09-29 00:00:48 - root - INFO -   Learning Rate: 0.000400
2025-09-29 00:00:48 - root - INFO - ------------------------------------------------------------
2025-09-29 00:00:49 - root - INFO - New best model saved with validation loss: 0.1071
2025-09-29 00:00:49 - root - INFO - Best model saved to: Baseline_B7/checkpoints/best_best_Baseline_B7_B_model.pth
2025-09-29 00:00:49 - root - INFO - Starting epoch 5/25
2025-09-29 00:02:07 - root - INFO -   Batch 50/269 - Loss: 0.0695, Acc: 93.50%
2025-09-29 00:03:18 - root - INFO -   Batch 100/269 - Loss: 0.0731, Acc: 92.38%
2025-09-29 00:04:32 - root - INFO -   Batch 150/269 - Loss: 0.0808, Acc: 92.25%
2025-09-29 00:05:43 - root - INFO -   Batch 200/269 - Loss: 0.0869, Acc: 91.31%
2025-09-29 00:06:57 - root - INFO -   Batch 250/269 - Loss: 0.0641, Acc: 91.30%
2025-09-29 00:07:23 - root - INFO - Running validation...
2025-09-29 00:11:04 - root - INFO - Checkpoint saved for epoch 5 at Baseline_B7/checkpoints/checkpoint_epoch_5.pth
2025-09-29 00:11:04 - root - INFO - Epoch 5/25 Results:
2025-09-29 00:11:04 - root - INFO -   Train Loss: 0.0828, Train Acc: 91.08%
2025-09-29 00:11:04 - root - INFO -   Val Loss: 0.1126, Val Acc: 77.85%
2025-09-29 00:11:04 - root - INFO -   Learning Rate: 0.000400
2025-09-29 00:11:04 - root - INFO - ------------------------------------------------------------
2025-09-29 00:11:04 - root - INFO - Starting epoch 6/25
2025-09-29 00:12:22 - root - INFO -   Batch 50/269 - Loss: 0.1040, Acc: 91.75%
2025-09-29 00:13:35 - root - INFO -   Batch 100/269 - Loss: 0.0693, Acc: 90.88%
2025-09-29 00:14:48 - root - INFO -   Batch 150/269 - Loss: 0.0583, Acc: 90.75%
2025-09-29 00:16:00 - root - INFO -   Batch 200/269 - Loss: 0.0886, Acc: 90.75%
2025-09-29 00:17:14 - root - INFO -   Batch 250/269 - Loss: 0.0794, Acc: 90.90%
2025-09-29 00:17:40 - root - INFO - Running validation...
2025-09-29 00:21:23 - root - INFO - Checkpoint saved for epoch 6 at Baseline_B7/checkpoints/checkpoint_epoch_6.pth
2025-09-29 00:21:23 - root - INFO - Epoch 6/25 Results:
2025-09-29 00:21:23 - root - INFO -   Train Loss: 0.0824, Train Acc: 90.71%
2025-09-29 00:21:23 - root - INFO -   Val Loss: 0.1111, Val Acc: 78.00%
2025-09-29 00:21:23 - root - INFO -   Learning Rate: 0.000400
2025-09-29 00:21:23 - root - INFO - ------------------------------------------------------------
2025-09-29 00:21:23 - root - INFO - Starting epoch 7/25
2025-09-29 00:22:41 - root - INFO -   Batch 50/269 - Loss: 0.0603, Acc: 90.75%
2025-09-29 00:23:54 - root - INFO -   Batch 100/269 - Loss: 0.0827, Acc: 91.50%
2025-09-29 00:25:08 - root - INFO -   Batch 150/269 - Loss: 0.0563, Acc: 92.00%
2025-09-29 00:26:21 - root - INFO -   Batch 200/269 - Loss: 0.0693, Acc: 92.00%
2025-09-29 00:27:35 - root - INFO -   Batch 250/269 - Loss: 0.0854, Acc: 92.15%
2025-09-29 00:28:02 - root - INFO - Running validation...
2025-09-29 00:31:42 - root - INFO - Checkpoint saved for epoch 7 at Baseline_B7/checkpoints/checkpoint_epoch_7.pth
2025-09-29 00:31:42 - root - INFO - Epoch 7/25 Results:
2025-09-29 00:31:42 - root - INFO -   Train Loss: 0.0795, Train Acc: 92.15%
2025-09-29 00:31:42 - root - INFO -   Val Loss: 0.1116, Val Acc: 78.75%
2025-09-29 00:31:42 - root - INFO -   Learning Rate: 0.000400
2025-09-29 00:31:42 - root - INFO - ------------------------------------------------------------
2025-09-29 00:31:42 - root - INFO - Starting epoch 8/25
2025-09-29 00:33:02 - root - INFO -   Batch 50/269 - Loss: 0.0697, Acc: 94.50%
2025-09-29 00:34:14 - root - INFO -   Batch 100/269 - Loss: 0.0701, Acc: 94.00%
2025-09-29 00:35:29 - root - INFO -   Batch 150/269 - Loss: 0.0924, Acc: 94.17%
2025-09-29 00:36:41 - root - INFO -   Batch 200/269 - Loss: 0.0746, Acc: 93.94%
2025-09-29 00:37:55 - root - INFO -   Batch 250/269 - Loss: 0.0926, Acc: 93.75%
2025-09-29 00:38:20 - root - INFO - Running validation...
2025-09-29 00:41:58 - root - INFO - Checkpoint saved for epoch 8 at Baseline_B7/checkpoints/checkpoint_epoch_8.pth
2025-09-29 00:41:58 - root - INFO - Epoch 8/25 Results:
2025-09-29 00:41:58 - root - INFO -   Train Loss: 0.0757, Train Acc: 93.77%
2025-09-29 00:41:58 - root - INFO -   Val Loss: 0.1213, Val Acc: 76.14%
2025-09-29 00:41:58 - root - INFO -   Learning Rate: 0.000400
2025-09-29 00:41:58 - root - INFO - ------------------------------------------------------------
2025-09-29 00:41:58 - root - INFO - Starting epoch 9/25
2025-09-29 00:43:14 - root - INFO -   Batch 50/269 - Loss: 0.0728, Acc: 93.50%
2025-09-29 00:44:27 - root - INFO -   Batch 100/269 - Loss: 0.1041, Acc: 94.38%
2025-09-29 00:45:37 - root - INFO -   Batch 150/269 - Loss: 0.0681, Acc: 94.75%
2025-09-29 00:46:49 - root - INFO -   Batch 200/269 - Loss: 0.0683, Acc: 95.25%
2025-09-29 00:48:01 - root - INFO -   Batch 250/269 - Loss: 0.0881, Acc: 94.35%
2025-09-29 00:48:27 - root - INFO - Running validation...
2025-09-29 00:52:04 - root - INFO - Checkpoint saved for epoch 9 at Baseline_B7/checkpoints/checkpoint_epoch_9.pth
2025-09-29 00:52:04 - root - INFO - Epoch 9/25 Results:
2025-09-29 00:52:04 - root - INFO -   Train Loss: 0.0742, Train Acc: 94.38%
2025-09-29 00:52:04 - root - INFO -   Val Loss: 0.1084, Val Acc: 81.66%
2025-09-29 00:52:04 - root - INFO -   Learning Rate: 0.000400
2025-09-29 00:52:04 - root - INFO - ------------------------------------------------------------
2025-09-29 00:52:04 - root - INFO - Starting epoch 10/25
2025-09-29 00:53:22 - root - INFO -   Batch 50/269 - Loss: 0.0610, Acc: 96.50%
2025-09-29 00:54:33 - root - INFO -   Batch 100/269 - Loss: 0.0568, Acc: 96.50%
2025-09-29 00:55:43 - root - INFO -   Batch 150/269 - Loss: 0.0766, Acc: 96.67%
2025-09-29 00:56:54 - root - INFO -   Batch 200/269 - Loss: 0.1082, Acc: 96.75%
2025-09-29 00:58:06 - root - INFO -   Batch 250/269 - Loss: 0.0757, Acc: 96.40%
2025-09-29 00:58:32 - root - INFO - Running validation...
2025-09-29 01:02:10 - root - INFO - Checkpoint saved for epoch 10 at Baseline_B7/checkpoints/checkpoint_epoch_10.pth
2025-09-29 01:02:10 - root - INFO - Epoch 10/25 Results:
2025-09-29 01:02:10 - root - INFO -   Train Loss: 0.0685, Train Acc: 96.28%
2025-09-29 01:02:10 - root - INFO -   Val Loss: 0.1105, Val Acc: 82.33%
2025-09-29 01:02:10 - root - INFO -   Learning Rate: 0.000400
2025-09-29 01:02:10 - root - INFO - ------------------------------------------------------------
2025-09-29 01:02:10 - root - INFO - Starting epoch 11/25
2025-09-29 01:03:28 - root - INFO -   Batch 50/269 - Loss: 0.0570, Acc: 96.00%
2025-09-29 01:04:42 - root - INFO -   Batch 100/269 - Loss: 0.0624, Acc: 95.50%
2025-09-29 01:05:55 - root - INFO -   Batch 150/269 - Loss: 0.0571, Acc: 95.58%
2025-09-29 01:07:08 - root - INFO -   Batch 200/269 - Loss: 0.0739, Acc: 95.62%
2025-09-29 01:08:21 - root - INFO -   Batch 250/269 - Loss: 0.0688, Acc: 95.85%
2025-09-29 01:08:47 - root - INFO - Running validation...
2025-09-29 01:12:30 - root - INFO - Checkpoint saved for epoch 11 at Baseline_B7/checkpoints/checkpoint_epoch_11.pth
2025-09-29 01:12:30 - root - INFO - Epoch 11/25 Results:
2025-09-29 01:12:30 - root - INFO -   Train Loss: 0.0702, Train Acc: 95.72%
2025-09-29 01:12:30 - root - INFO -   Val Loss: 0.1131, Val Acc: 80.91%
2025-09-29 01:12:30 - root - INFO -   Learning Rate: 0.000400
2025-09-29 01:12:30 - root - INFO - ------------------------------------------------------------
2025-09-29 01:12:30 - root - INFO - Starting epoch 12/25
2025-09-29 01:13:48 - root - INFO -   Batch 50/269 - Loss: 0.0596, Acc: 97.25%
2025-09-29 01:15:03 - root - INFO -   Batch 100/269 - Loss: 0.0580, Acc: 97.12%
2025-09-29 01:16:19 - root - INFO -   Batch 150/269 - Loss: 0.0653, Acc: 97.00%
2025-09-29 01:17:34 - root - INFO -   Batch 200/269 - Loss: 0.2120, Acc: 96.94%
2025-09-29 01:18:49 - root - INFO -   Batch 250/269 - Loss: 0.0633, Acc: 95.60%
2025-09-29 01:19:16 - root - INFO - Running validation...
2025-09-29 01:23:08 - root - INFO - Checkpoint saved for epoch 12 at Baseline_B7/checkpoints/checkpoint_epoch_12.pth
2025-09-29 01:23:08 - root - INFO - Epoch 12/25 Results:
2025-09-29 01:23:08 - root - INFO -   Train Loss: 0.0702, Train Acc: 95.54%
2025-09-29 01:23:08 - root - INFO -   Val Loss: 0.1136, Val Acc: 80.16%
2025-09-29 01:23:08 - root - INFO -   Learning Rate: 0.000400
2025-09-29 01:23:08 - root - INFO - ------------------------------------------------------------
2025-09-29 01:23:08 - root - INFO - Starting epoch 13/25
2025-09-29 01:24:30 - root - INFO -   Batch 50/269 - Loss: 0.0566, Acc: 97.50%
2025-09-29 01:25:43 - root - INFO -   Batch 100/269 - Loss: 0.0613, Acc: 97.25%
2025-09-29 01:27:00 - root - INFO -   Batch 150/269 - Loss: 0.0668, Acc: 96.67%
2025-09-29 01:28:14 - root - INFO -   Batch 200/269 - Loss: 0.0659, Acc: 96.25%
2025-09-29 01:29:30 - root - INFO -   Batch 250/269 - Loss: 0.0748, Acc: 95.40%
2025-09-29 01:29:56 - root - INFO - Running validation...
2025-09-29 01:33:43 - root - INFO - Checkpoint saved for epoch 13 at Baseline_B7/checkpoints/checkpoint_epoch_13.pth
2025-09-29 01:33:43 - root - INFO - Epoch 13/25 Results:
2025-09-29 01:33:43 - root - INFO -   Train Loss: 0.0708, Train Acc: 95.49%
2025-09-29 01:33:43 - root - INFO -   Val Loss: 0.1184, Val Acc: 78.37%
2025-09-29 01:33:43 - root - INFO -   Learning Rate: 0.000400
2025-09-29 01:33:43 - root - INFO - ------------------------------------------------------------
2025-09-29 01:33:43 - root - INFO - Starting epoch 14/25
2025-09-29 01:35:03 - root - INFO -   Batch 50/269 - Loss: 0.0589, Acc: 98.25%
2025-09-29 01:36:19 - root - INFO -   Batch 100/269 - Loss: 0.0944, Acc: 96.75%
2025-09-29 01:37:36 - root - INFO -   Batch 150/269 - Loss: 0.0649, Acc: 97.08%
2025-09-29 01:38:50 - root - INFO -   Batch 200/269 - Loss: 0.0877, Acc: 96.62%
2025-09-29 01:40:06 - root - INFO -   Batch 250/269 - Loss: 0.0578, Acc: 96.35%
2025-09-29 01:40:33 - root - INFO - Running validation...
2025-09-29 01:44:20 - root - INFO - Checkpoint saved for epoch 14 at Baseline_B7/checkpoints/checkpoint_epoch_14.pth
2025-09-29 01:44:20 - root - INFO - Epoch 14/25 Results:
2025-09-29 01:44:20 - root - INFO -   Train Loss: 0.0667, Train Acc: 96.51%
2025-09-29 01:44:20 - root - INFO -   Val Loss: 0.1061, Val Acc: 82.85%
2025-09-29 01:44:20 - root - INFO -   Learning Rate: 0.000400
2025-09-29 01:44:20 - root - INFO - ------------------------------------------------------------
2025-09-29 01:44:21 - root - INFO - New best model saved with validation loss: 0.1061
2025-09-29 01:44:21 - root - INFO - Best model saved to: Baseline_B7/checkpoints/best_best_Baseline_B7_B_model.pth
2025-09-29 01:44:21 - root - INFO - Starting epoch 15/25
2025-09-29 01:45:40 - root - INFO -   Batch 50/269 - Loss: 0.0574, Acc: 97.00%
2025-09-29 01:46:57 - root - INFO -   Batch 100/269 - Loss: 0.0739, Acc: 96.62%
2025-09-29 01:48:12 - root - INFO -   Batch 150/269 - Loss: 0.1097, Acc: 96.25%
2025-09-29 01:49:29 - root - INFO -   Batch 200/269 - Loss: 0.1045, Acc: 96.19%
2025-09-29 01:50:44 - root - INFO -   Batch 250/269 - Loss: 0.1060, Acc: 96.35%
2025-09-29 01:51:11 - root - INFO - Running validation...
2025-09-29 01:54:58 - root - INFO - Checkpoint saved for epoch 15 at Baseline_B7/checkpoints/checkpoint_epoch_15.pth
2025-09-29 01:54:58 - root - INFO - Epoch 15/25 Results:
2025-09-29 01:54:58 - root - INFO -   Train Loss: 0.0677, Train Acc: 96.14%
2025-09-29 01:54:58 - root - INFO -   Val Loss: 0.1264, Val Acc: 75.84%
2025-09-29 01:54:58 - root - INFO -   Learning Rate: 0.000400
2025-09-29 01:54:58 - root - INFO - ------------------------------------------------------------
2025-09-29 01:54:58 - root - INFO - Starting epoch 16/25
2025-09-29 01:56:18 - root - INFO -   Batch 50/269 - Loss: 0.0618, Acc: 95.75%
2025-09-29 01:57:32 - root - INFO -   Batch 100/269 - Loss: 0.0626, Acc: 96.00%
2025-09-29 01:58:48 - root - INFO -   Batch 150/269 - Loss: 0.0575, Acc: 96.00%
2025-09-29 02:00:04 - root - INFO -   Batch 200/269 - Loss: 0.0568, Acc: 95.62%
2025-09-29 02:01:20 - root - INFO -   Batch 250/269 - Loss: 0.0569, Acc: 95.55%
2025-09-29 02:01:47 - root - INFO - Running validation...
2025-09-29 02:05:39 - root - INFO - Checkpoint saved for epoch 16 at Baseline_B7/checkpoints/checkpoint_epoch_16.pth
2025-09-29 02:05:39 - root - INFO - Epoch 16/25 Results:
2025-09-29 02:05:39 - root - INFO -   Train Loss: 0.0698, Train Acc: 95.45%
2025-09-29 02:05:39 - root - INFO -   Val Loss: 0.1152, Val Acc: 79.05%
2025-09-29 02:05:39 - root - INFO -   Learning Rate: 0.000400
2025-09-29 02:05:39 - root - INFO - ------------------------------------------------------------
2025-09-29 02:05:39 - root - INFO - Starting epoch 17/25
2025-09-29 02:07:01 - root - INFO -   Batch 50/269 - Loss: 0.0612, Acc: 98.50%
2025-09-29 02:08:15 - root - INFO -   Batch 100/269 - Loss: 0.0595, Acc: 98.00%
2025-09-29 02:09:30 - root - INFO -   Batch 150/269 - Loss: 0.0615, Acc: 97.75%
2025-09-29 02:10:43 - root - INFO -   Batch 200/269 - Loss: 0.0858, Acc: 97.25%
2025-09-29 02:11:56 - root - INFO -   Batch 250/269 - Loss: 0.0589, Acc: 97.30%
2025-09-29 02:12:23 - root - INFO - Running validation...
2025-09-29 02:16:08 - root - INFO - Checkpoint saved for epoch 17 at Baseline_B7/checkpoints/checkpoint_epoch_17.pth
2025-09-29 02:16:08 - root - INFO - Epoch 17/25 Results:
2025-09-29 02:16:08 - root - INFO -   Train Loss: 0.0669, Train Acc: 97.26%
2025-09-29 02:16:08 - root - INFO -   Val Loss: 0.1116, Val Acc: 81.36%
2025-09-29 02:16:08 - root - INFO -   Learning Rate: 0.000400
2025-09-29 02:16:08 - root - INFO - ------------------------------------------------------------
2025-09-29 02:16:08 - root - INFO - Starting epoch 18/25
2025-09-29 02:17:28 - root - INFO -   Batch 50/269 - Loss: 0.0639, Acc: 98.75%
2025-09-29 02:18:42 - root - INFO -   Batch 100/269 - Loss: 0.0633, Acc: 97.25%
2025-09-29 02:19:57 - root - INFO -   Batch 150/269 - Loss: 0.0582, Acc: 97.08%
2025-09-29 02:21:10 - root - INFO -   Batch 200/269 - Loss: 0.0744, Acc: 97.38%
2025-09-29 02:22:25 - root - INFO -   Batch 250/269 - Loss: 0.0584, Acc: 97.15%
2025-09-29 02:22:52 - root - INFO - Running validation...
2025-09-29 02:26:40 - root - INFO - Checkpoint saved for epoch 18 at Baseline_B7/checkpoints/checkpoint_epoch_18.pth
2025-09-29 02:26:40 - root - INFO - Epoch 18/25 Results:
2025-09-29 02:26:40 - root - INFO -   Train Loss: 0.0648, Train Acc: 96.98%
2025-09-29 02:26:40 - root - INFO -   Val Loss: 0.1145, Val Acc: 81.88%
2025-09-29 02:26:40 - root - INFO -   Learning Rate: 0.000400
2025-09-29 02:26:40 - root - INFO - ------------------------------------------------------------
2025-09-29 02:26:40 - root - INFO - Starting epoch 19/25
2025-09-29 02:28:02 - root - INFO -   Batch 50/269 - Loss: 0.0574, Acc: 94.00%
2025-09-29 02:29:16 - root - INFO -   Batch 100/269 - Loss: 0.0583, Acc: 96.12%
2025-09-29 02:30:32 - root - INFO -   Batch 150/269 - Loss: 0.0654, Acc: 96.17%
2025-09-29 02:31:47 - root - INFO -   Batch 200/269 - Loss: 0.0935, Acc: 95.81%
2025-09-29 02:33:01 - root - INFO -   Batch 250/269 - Loss: 0.0764, Acc: 95.70%
2025-09-29 02:33:28 - root - INFO - Running validation...
2025-09-29 02:37:15 - root - INFO - Checkpoint saved for epoch 19 at Baseline_B7/checkpoints/checkpoint_epoch_19.pth
2025-09-29 02:37:15 - root - INFO - Epoch 19/25 Results:
2025-09-29 02:37:15 - root - INFO -   Train Loss: 0.0685, Train Acc: 95.49%
2025-09-29 02:37:15 - root - INFO -   Val Loss: 0.1093, Val Acc: 81.58%
2025-09-29 02:37:15 - root - INFO -   Learning Rate: 0.000400
2025-09-29 02:37:15 - root - INFO - ------------------------------------------------------------
2025-09-29 02:37:15 - root - INFO - Starting epoch 20/25
2025-09-29 02:38:34 - root - INFO -   Batch 50/269 - Loss: 0.0578, Acc: 95.00%
2025-09-29 02:39:48 - root - INFO -   Batch 100/269 - Loss: 0.0777, Acc: 95.12%
2025-09-29 02:41:03 - root - INFO -   Batch 150/269 - Loss: 0.0576, Acc: 95.00%
2025-09-29 02:42:17 - root - INFO -   Batch 200/269 - Loss: 0.0567, Acc: 95.56%
2025-09-29 02:43:33 - root - INFO -   Batch 250/269 - Loss: 0.0590, Acc: 95.35%
2025-09-29 02:43:59 - root - INFO - Running validation...
2025-09-29 02:47:44 - root - INFO - Checkpoint saved for epoch 20 at Baseline_B7/checkpoints/checkpoint_epoch_20.pth
2025-09-29 02:47:44 - root - INFO - Epoch 20/25 Results:
2025-09-29 02:47:44 - root - INFO -   Train Loss: 0.0690, Train Acc: 95.40%
2025-09-29 02:47:44 - root - INFO -   Val Loss: 0.1223, Val Acc: 79.72%
2025-09-29 02:47:44 - root - INFO -   Learning Rate: 0.000400
2025-09-29 02:47:44 - root - INFO - ------------------------------------------------------------
2025-09-29 02:47:44 - root - INFO - Starting epoch 21/25
2025-09-29 02:49:06 - root - INFO -   Batch 50/269 - Loss: 0.0565, Acc: 98.00%
2025-09-29 02:50:23 - root - INFO -   Batch 100/269 - Loss: 0.0560, Acc: 97.62%
2025-09-29 02:51:41 - root - INFO -   Batch 150/269 - Loss: 0.0597, Acc: 97.17%
2025-09-29 02:52:56 - root - INFO -   Batch 200/269 - Loss: 0.0727, Acc: 97.38%
2025-09-29 02:54:11 - root - INFO -   Batch 250/269 - Loss: 0.0621, Acc: 97.00%
2025-09-29 02:54:38 - root - INFO - Running validation...
2025-09-29 02:58:20 - root - INFO - Checkpoint saved for epoch 21 at Baseline_B7/checkpoints/checkpoint_epoch_21.pth
2025-09-29 02:58:20 - root - INFO - Epoch 21/25 Results:
2025-09-29 02:58:20 - root - INFO -   Train Loss: 0.0656, Train Acc: 96.93%
2025-09-29 02:58:20 - root - INFO -   Val Loss: 0.1237, Val Acc: 78.52%
2025-09-29 02:58:20 - root - INFO -   Learning Rate: 0.000400
2025-09-29 02:58:20 - root - INFO - ------------------------------------------------------------
2025-09-29 02:58:20 - root - INFO - Starting epoch 22/25
2025-09-29 02:59:39 - root - INFO -   Batch 50/269 - Loss: 0.0583, Acc: 96.75%
2025-09-29 03:00:52 - root - INFO -   Batch 100/269 - Loss: 0.0579, Acc: 96.38%
2025-09-29 03:02:05 - root - INFO -   Batch 150/269 - Loss: 0.0778, Acc: 96.08%
2025-09-29 03:03:18 - root - INFO -   Batch 200/269 - Loss: 0.0656, Acc: 95.31%
2025-09-29 03:04:32 - root - INFO -   Batch 250/269 - Loss: 0.0568, Acc: 95.35%
2025-09-29 03:04:58 - root - INFO - Running validation...
2025-09-29 03:08:37 - root - INFO - Checkpoint saved for epoch 22 at Baseline_B7/checkpoints/checkpoint_epoch_22.pth
2025-09-29 03:08:37 - root - INFO - Epoch 22/25 Results:
2025-09-29 03:08:37 - root - INFO -   Train Loss: 0.0697, Train Acc: 95.26%
2025-09-29 03:08:37 - root - INFO -   Val Loss: 0.1305, Val Acc: 73.83%
2025-09-29 03:08:37 - root - INFO -   Learning Rate: 0.000400
2025-09-29 03:08:37 - root - INFO - ------------------------------------------------------------
2025-09-29 03:08:37 - root - INFO - Starting epoch 23/25
2025-09-29 03:09:54 - root - INFO -   Batch 50/269 - Loss: 0.0598, Acc: 95.50%
2025-09-29 03:11:06 - root - INFO -   Batch 100/269 - Loss: 0.0712, Acc: 95.75%
2025-09-29 03:12:24 - root - INFO -   Batch 150/269 - Loss: 0.0582, Acc: 96.50%
2025-09-29 03:13:38 - root - INFO -   Batch 200/269 - Loss: 0.0569, Acc: 96.19%
2025-09-29 03:14:54 - root - INFO -   Batch 250/269 - Loss: 0.0783, Acc: 95.90%
2025-09-29 03:15:21 - root - INFO - Running validation...
2025-09-29 03:19:02 - root - INFO - Checkpoint saved for epoch 23 at Baseline_B7/checkpoints/checkpoint_epoch_23.pth
2025-09-29 03:19:02 - root - INFO - Epoch 23/25 Results:
2025-09-29 03:19:02 - root - INFO -   Train Loss: 0.0678, Train Acc: 96.00%
2025-09-29 03:19:02 - root - INFO -   Val Loss: 0.1206, Val Acc: 79.05%
2025-09-29 03:19:02 - root - INFO -   Learning Rate: 0.000400
2025-09-29 03:19:02 - root - INFO - ------------------------------------------------------------
2025-09-29 03:19:02 - root - INFO - Starting epoch 24/25
2025-09-29 03:20:22 - root - INFO -   Batch 50/269 - Loss: 0.0574, Acc: 94.25%
2025-09-29 03:21:34 - root - INFO -   Batch 100/269 - Loss: 0.0735, Acc: 93.62%
2025-09-29 03:22:50 - root - INFO -   Batch 150/269 - Loss: 0.0899, Acc: 94.17%
2025-09-29 03:24:02 - root - INFO -   Batch 200/269 - Loss: 0.0570, Acc: 94.31%
2025-09-29 03:25:18 - root - INFO -   Batch 250/269 - Loss: 0.0754, Acc: 94.85%
2025-09-29 03:25:44 - root - INFO - Running validation...
2025-09-29 03:29:24 - root - INFO - Checkpoint saved for epoch 24 at Baseline_B7/checkpoints/checkpoint_epoch_24.pth
2025-09-29 03:29:24 - root - INFO - Epoch 24/25 Results:
2025-09-29 03:29:24 - root - INFO -   Train Loss: 0.0701, Train Acc: 95.07%
2025-09-29 03:29:24 - root - INFO -   Val Loss: 0.1246, Val Acc: 78.23%
2025-09-29 03:29:24 - root - INFO -   Learning Rate: 0.000400
2025-09-29 03:29:24 - root - INFO - ------------------------------------------------------------
2025-09-29 03:29:24 - root - INFO - Starting epoch 25/25
2025-09-29 03:30:42 - root - INFO -   Batch 50/269 - Loss: 0.0697, Acc: 97.25%
2025-09-29 03:31:53 - root - INFO -   Batch 100/269 - Loss: 0.0695, Acc: 96.38%
2025-09-29 03:33:06 - root - INFO -   Batch 150/269 - Loss: 0.0709, Acc: 96.33%
2025-09-29 03:34:19 - root - INFO -   Batch 200/269 - Loss: 0.0986, Acc: 95.31%
2025-09-29 03:35:33 - root - INFO -   Batch 250/269 - Loss: 0.0665, Acc: 95.30%
2025-09-29 03:35:58 - root - INFO - Running validation...
2025-09-29 03:39:42 - root - INFO - Checkpoint saved for epoch 25 at Baseline_B7/checkpoints/checkpoint_epoch_25.pth
2025-09-29 03:39:42 - root - INFO - Epoch 25/25 Results:
2025-09-29 03:39:42 - root - INFO -   Train Loss: 0.0705, Train Acc: 95.17%
2025-09-29 03:39:42 - root - INFO -   Val Loss: 0.1095, Val Acc: 80.98%
2025-09-29 03:39:42 - root - INFO -   Learning Rate: 0.000400
2025-09-29 03:39:42 - root - INFO - ------------------------------------------------------------
2025-09-29 03:39:42 - root - INFO - Training completed!
2025-09-29 03:39:42 - root - INFO - Best validation loss achieved: 0.1061
2025-09-29 03:39:42 - root - INFO - Loading best model for final evaluation...
2025-09-29 03:43:26 - root - INFO - Final validation accuracy: 82.85%
2025-09-29 03:43:26 - root - INFO - training completed successfully
